import pandas as pdimport numpy as npimport os #os è un libreria per individuare la directory dove ci si trovafrom datetime import datetime, timefrom sklearn import tree#import weka.core.jvm as jvmfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_scorefrom sklearn.ensemble import RandomForestRegressorfrom sklearn.preprocessing import StandardScalerfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate, ShuffleSplitfrom sklearn import metricsfrom sklearn import datasetsfrom sklearn.multiclass import OutputCodeClassifierfrom sklearn.svm import *from sklearn.naive_bayes import MultinomialNBimport sklearnfrom sklearn import svmfrom sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifierimport imblearnfrom imblearn.pipeline import Pipelinefrom imblearn.over_sampling import SMOTEfrom imblearn.combine import SMOTEENNfrom sklearn.linear_model import LogisticRegressionfrom sklearn.linear_model import Perceptronfrom collections import Counterfrom sklearn.datasets import make_classificationfrom matplotlib import pyplotfrom numpy import whereimport numpyfrom imblearn.under_sampling import NearMissimport matplotlib.pyplot as plt# Training set uploadtraining = pd.read_csv('/Users/giulia/Unimib/Data Science Lab/progetto fastweb/progettodslab/training.csv', sep=';')    # verifica valori null all'interno del trainingtraining = training.dropna()len(training['KIT_ID'].unique())counter = Counter(training['KIT_ID'])print(counter)#Trasformazione TS in datetimetraining['TS'] = pd.to_datetime(training['TS'])#training['TS'] = pd.to_numeric(training['TS'], downcast='float', errors='ignore')# type(training.loc[0,'TS'] )training.loc[0,'TS']print('0 ' + str(len(training[training['VAR_CLASS'] == 0])))#16521526print('1 ' + str(len(training[training['VAR_CLASS'] == 1])))#36print('2 ' + str(len(training[training['VAR_CLASS'] == 2])))#472str(len(training[training['VAR_CLASS'] == 2]))#Analisi TStraining['TS'] = pd.to_datetime(training['TS'])training['TS'].dt.year.unique()#2018training['TS'].dt.month.unique()#11training['TS'].dt.day.unique()#1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30training['VAR_CLASS'].unique()#1,2,3training[training['NUM_CLI'] >= 100]# training['USAGE'].sort_values(ascending=True)trainingOrderByUSAGE = training.sort_values(by=['USAGE'])trainingOrderByAVG = training.sort_values(by=['AVG_SPEED_DW'])training.describe().apply(lambda s: s.apply(lambda x: format(x, 'g')))training['KIT_ID'].describe()descriptiveQuantity = training[['USAGE','AVG_SPEED_DW','NUM_CLI']].describe().apply(lambda s: s.apply(lambda x: format(x, 'g')))descriptiveQuantity# CREO DIVERSI DATAFRAME PER KIT_ID# kit_id1 3409364152 # kit_id2 1629361016# kit_id3 2487219358 training_diff_kit = training[(training['KIT_ID']!=3409364152) &                             (training['KIT_ID']!=1629361016) &                             (training['KIT_ID']!=2487219358)]training_kit_id1 = training[training.KIT_ID==3409364152]training_kit_id2 = training[training.KIT_ID==1629361016]training_kit_id3 = training[training.KIT_ID==2487219358]def prepareTraining():       epoch = datetime.utcfromtimestamp(0)    training['TS'] = pd.to_datetime(training['TS'])    training['TS'] = training['TS'] - epoch    training['TS'] = training['TS'].dt.total_seconds()        X = training[['TS','USAGE','NUM_CLI']]    y = training['VAR_CLASS']        X = X.to_numpy()    y = y.to_numpy()    return (X,y)X, y = prepareTraining()X.shapey.shape#In terms of machine learning, Clf is an estimator instance, which is used to store model.#We use clf to store trained model values, which are further used to predict value, based on the previously stored weights.# Generate a synthetic imbalanced classification dataset#Synthetic Minority Over-sampling Techniqueoversample = SMOTE(random_state=100,k_neighbors=2)X, y = oversample.fit_resample(X, y)counter = Counter(y)print(counter)#### split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)## definisco il datasetX, y = make_classification() # NON RUNNO ORAprint(training[training['VAR_CLASS']==2])# training.len==3455############################################################################from random import sample, randintimport randomtraining_copy = trainingdef random_subset(training):    length = randint(3455, len(training))    return set(sample(training, length))training_copy = random_subset(set)print(random.sample(training_copy,3455))np.random.seed(1234)country_unknown['country_code'] = np.random.choice(freq_country['country_code'], size=len(country_unknown.index), p = freq_country['perc_distr'])np.random.seed(1234)training_copia['KIT_ID'] = np.random.choice(training['KIT_ID'], size=3455)############################################################################## PROVA### subset di 3455 per comparare al kit id 3 accuracy=0.3278### subset di 8348 per comparare al kit id 2 accuracy=0.3363### subset di 8632 per comparare al kit id 1 accuracy=0.3374training_corto = training_copy.sample(n=8632, random_state=1234)##### prova allenare questo datasetdef prepareTraining():       epoch = datetime.utcfromtimestamp(0)    training_corto['TS'] = pd.to_datetime(training_corto['TS'])    training_corto['TS'] = training_corto['TS'] - epoch    training_corto['TS'] = training_corto['TS'].dt.total_seconds()        X_corto = training_corto[['TS','USAGE','NUM_CLI']]    y_corto3 = training_kit_id1['VAR_CLASS']        X_corto = X_corto.to_numpy()    y_corto3 = y_corto3.to_numpy()    return (X_corto,y_corto3)X_corto, y_corto3 = prepareTraining()X_corto.shapey_corto3.shapeoversample_corto = SMOTE(random_state=100,k_neighbors=2)X_corto, y_corto3 = oversample_corto.fit_resample(X_corto, y_corto3)counter = Counter(y_corto3)print(counter)X_corto_train, X_corto_test, y_corto3_train, y_corto3_test = train_test_split(X_corto, y_corto3, test_size=0.3, random_state=0)## definisco il modellomodello_corto = LogisticRegression(multi_class='ovr')## fitto il modellomodello_corto.fit(X_corto_train, y_corto3_train)## eseguo predizioney_corto3_pred_lr = modello_corto.predict(X_corto_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion_corto = confusion_matrix(y_corto3_test, y_corto3_pred_lr)print('Confusion Matrix\n')print(confusion_corto)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y_corto3_test, y_corto3_pred_lr)))######################################################################################################## MODELLO TRAINING ######################################################################################################### definisco il modellomodelLRovr = LogisticRegression(multi_class='ovr')## fitto il modellomodelLRovr.fit(X_train, y_train)## eseguo predizioney_pred_lr = modelLRovr.predict(X_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion = confusion_matrix(y_test, y_pred_lr)print('Confusion Matrix\n')print(confusion)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y_test, y_pred_lr)))print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred_lr, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred_lr, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y_test, y_pred_lr, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred_lr, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred_lr, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y_test, y_pred_lr, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred_lr, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred_lr, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred_lr, average='weighted')))print('\nClassification Report\n')print(classification_report(y_test, y_pred_lr, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_lr))print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_lr))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_lr)))########################### PERCEPTRON 0 #############################ppn = Perceptron(max_iter=40, tol=0.001, eta0=0.01, random_state=0)# fitto il modelloppn.fit(X_train, y_train) # eseguo la predizioney_pred_ppn = ppn.predict(X_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion_ppn = confusion_matrix(y_test, y_pred_ppn)print('Confusion Matrix\n')print(confusion_ppn)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y_test, y_pred_ppn)))print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred_ppn, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred_ppn, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y_test, y_pred_ppn, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred_ppn, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred_ppn, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y_test, y_pred_ppn, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred_ppn, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred_ppn, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred_ppn, average='weighted')))print('\nClassification Report\n')print(classification_report(y_test, y_pred_ppn, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_ppn))print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_ppn))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_ppn)))##################################################################################################### MODELLO TRAINING KIT_ID1 ##################################################################################################def prepareTraining():       epoch = datetime.utcfromtimestamp(0)    training_kit_id1['TS'] = pd.to_datetime(training_kit_id1['TS'])    training_kit_id1['TS'] = training_kit_id1['TS'] - epoch    training_kit_id1['TS'] = training_kit_id1['TS'].dt.total_seconds()        X1 = training_kit_id1[['TS','USAGE','NUM_CLI']]    y1 = training_kit_id1['VAR_CLASS']        X1 = X1.to_numpy()    y1 = y1.to_numpy()    return (X1,y1)X1, y1 = prepareTraining()oversample1 = SMOTE(random_state=100,k_neighbors=2)X1, y1 = oversample1.fit_resample(X1, y1)counter = Counter(y1)print(counter)X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=0)modelLRkitid1 = LogisticRegression(multi_class='ovr')# fitmodelLRkitid1.fit(X1_train, y1_train)# predizioney1_pred_lr = modelLRkitid1.predict(X1_test)confusion1 = confusion_matrix(y1_test, y1_pred_lr)print('Confusion Matrix\n')print(confusion1)print('\nAccuracy: {:.4f}\n'.format(accuracy_score(y1_test, y1_pred_lr)))#accuracy_score, precision_score, recall_score, f1_scoreprint('Micro Precision: {:.2f}'.format(precision_score(y1_test, y1_pred_lr, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y1_test, y1_pred_lr, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y1_test, y1_pred_lr, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y1_test, y1_pred_lr, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y1_test, y1_pred_lr, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y1_test, y1_pred_lr, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y1_test, y1_pred_lr, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y1_test, y1_pred_lr, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y1_test, y1_pred_lr, average='weighted')))print('\nClassification Report\n')print(classification_report(y1_test, y1_pred_lr, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y1_test, y1_pred_lr))print('Mean Squared Error:', metrics.mean_squared_error(y1_test, y1_pred_lr))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y1_test, y1_pred_lr)))########################### PERCEPTRON 1 #############################ppn1 = Perceptron(max_iter=40, tol=0.001, eta0=0.01, random_state=0)# fitto il modelloppn1.fit(X1_train, y1_train) # eseguo la predizioney1_pred_ppn = ppn1.predict(X1_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion_ppn1 = confusion_matrix(y1_test, y1_pred_ppn)print('Confusion Matrix\n')print(confusion_ppn1)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y1_test, y1_pred_ppn)))print('Micro Precision: {:.2f}'.format(precision_score(y1_test, y1_pred_ppn, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y1_test, y1_pred_ppn, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y1_test, y1_pred_ppn, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y1_test, y1_pred_ppn, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y1_test, y1_pred_ppn, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y1_test, y1_pred_ppn, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y1_test, y1_pred_ppn, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y1_test, y1_pred_ppn, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y1_test, y1_pred_ppn, average='weighted')))print('\nClassification Report\n')print(classification_report(y1_test, y1_pred_ppn, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y1_test, y1_pred_ppn))print('Mean Squared Error:', metrics.mean_squared_error(y1_test, y1_pred_ppn))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y1_test, y1_pred_ppn)))##################################################################################################### MODELLO TRAINING KIT_ID2 ##################################################################################################def prepareTraining():       epoch = datetime.utcfromtimestamp(0)    training_kit_id2['TS'] = pd.to_datetime(training_kit_id2['TS'])    training_kit_id2['TS'] = training_kit_id2['TS'] - epoch    training_kit_id2['TS'] = training_kit_id2['TS'].dt.total_seconds()        X2 = training_kit_id2[['TS','USAGE','NUM_CLI']]    y2 = training_kit_id2['VAR_CLASS']        X2 = X2.to_numpy()    y2 = y2.to_numpy()    return (X2,y2)X2, y2 = prepareTraining()oversample2 = SMOTE(random_state=100,k_neighbors=2)X2, y2 = oversample2.fit_resample(X2, y2)counter = Counter(y2)print(counter)X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=0)modelLRkitid2 = LogisticRegression(multi_class='ovr')# fitmodelLRkitid2.fit(X2_train, y2_train)# predizioney2_pred_lr = modelLRkitid1.predict(X2_test)confusion2 = confusion_matrix(y2_test, y2_pred_lr)print('Confusion Matrix\n')print(confusion2)print('\nAccuracy: {:.4f}\n'.format(accuracy_score(y2_test, y2_pred_lr)))#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y2_test, y2_pred_lr)))print('Micro Precision: {:.2f}'.format(precision_score(y2_test, y2_pred_lr, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y2_test, y2_pred_lr, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y2_test, y2_pred_lr, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y2_test, y2_pred_lr, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y2_test, y2_pred_lr, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y2_test, y2_pred_lr, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y2_test, y2_pred_lr, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y2_test, y2_pred_lr, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y2_test, y2_pred_lr, average='weighted')))print('\nClassification Report\n')print(classification_report(y2_test, y2_pred_lr, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y2_test, y2_pred_lr))print('Mean Squared Error:', metrics.mean_squared_error(y2_test, y2_pred_lr))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_lr)))########################### PERCEPTRON 2 #############################ppn2 = Perceptron(max_iter=40, tol=0.001, eta0=0.01, random_state=0)# fitto il modelloppn2.fit(X2_train, y2_train) # eseguo la predizioney2_pred_ppn = ppn2.predict(X2_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion_ppn2 = confusion_matrix(y2_test, y2_pred_ppn)print('Confusion Matrix\n')print(confusion_ppn2)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y2_test, y2_pred_ppn)))print('Micro Precision: {:.2f}'.format(precision_score(y2_test, y2_pred_ppn, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y2_test, y2_pred_ppn, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y2_test, y2_pred_ppn, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y2_test, y2_pred_ppn, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y2_test, y2_pred_ppn, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y2_test, y2_pred_ppn, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y2_test, y2_pred_ppn, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y2_test, y2_pred_ppn, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y2_test, y2_pred_ppn, average='weighted')))print('\nClassification Report\n')print(classification_report(y2_test, y2_pred_ppn, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y2_test, y2_pred_ppn))print('Mean Squared Error:', metrics.mean_squared_error(y2_test, y2_pred_ppn))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_ppn)))    ##################################################################################################### MODELLO TRAINING KIT_ID3 ##################################################################################################def prepareTraining():       epoch = datetime.utcfromtimestamp(0)    training_kit_id3['TS'] = pd.to_datetime(training_kit_id3['TS'])    training_kit_id3['TS'] = training_kit_id3['TS'] - epoch    training_kit_id3['TS'] = training_kit_id3['TS'].dt.total_seconds()        X3 = training_kit_id3[['TS','USAGE','NUM_CLI']]    y3 = training_kit_id3['VAR_CLASS']        X3 = X3.to_numpy()    y3 = y3.to_numpy()    return (X3,y3)X3, y3 = prepareTraining()oversample3 = SMOTE(random_state=100,k_neighbors=2)X3, y3 = oversample3.fit_resample(X3, y3)counter = Counter(y3)print(counter)X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=0)modelLRkitid3 = LogisticRegression(multi_class='ovr')# fitmodelLRkitid3.fit(X3_train, y3_train)# predizioney3_pred_lr = modelLRkitid3.predict(X3_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion3 = confusion_matrix(y3_test, y3_pred_lr)print('Confusion Matrix\n')print(confusion3)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y3_test, y3_pred_lr)))print('Micro Precision: {:.2f}'.format(precision_score(y3_test, y3_pred_lr, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y3_test, y3_pred_lr, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y3_test, y3_pred_lr, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y3_test, y3_pred_lr, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y3_test, y3_pred_lr, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y3_test, y3_pred_lr, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y3_test, y3_pred_lr, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y3_test, y3_pred_lr, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y3_test, y3_pred_lr, average='weighted')))print('\nClassification Report\n')print(classification_report(y3_test, y3_pred_lr, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y3_test, y3_pred_lr))print('Mean Squared Error:', metrics.mean_squared_error(y3_test, y3_pred_lr))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y3_test, y3_pred_lr)))########################### PERCEPTRON 3 #############################ppn3 = Perceptron(max_iter=40, tol=0.001, eta0=0.01, random_state=0)# fitto il modelloppn3.fit(X3_train, y3_train) # eseguo la predizioney3_pred_ppn = ppn3.predict(X3_test)#### PROVA CONFUSION MATRIX FOR MULTICLASS ####confusion_ppn3 = confusion_matrix(y3_test, y3_pred_ppn)print('Confusion Matrix\n')print(confusion_ppn3)#accuracy_score, precision_score, recall_score, f1_scoreprint('\nAccuracy: {:.4f}\n'.format(accuracy_score(y3_test, y3_pred_ppn)))print('Micro Precision: {:.2f}'.format(precision_score(y3_test, y3_pred_ppn, average='micro')))print('Micro Recall: {:.2f}'.format(recall_score(y3_test, y3_pred_ppn, average='micro')))print('Micro F1-score: {:.2f}\n'.format(f1_score(y3_test, y3_pred_ppn, average='micro')))print('Macro Precision: {:.2f}'.format(precision_score(y3_test, y3_pred_ppn, average='macro')))print('Macro Recall: {:.2f}'.format(recall_score(y3_test, y3_pred_ppn, average='macro')))print('Macro F1-score: {:.2f}\n'.format(f1_score(y3_test, y3_pred_ppn, average='macro')))print('Weighted Precision: {:.2f}'.format(precision_score(y3_test, y3_pred_ppn, average='weighted')))print('Weighted Recall: {:.2f}'.format(recall_score(y3_test, y3_pred_ppn, average='weighted')))print('Weighted F1-score: {:.2f}'.format(f1_score(y3_test, y3_pred_ppn, average='weighted')))print('\nClassification Report\n')print(classification_report(y3_test, y3_pred_ppn, target_names=['Var_Class 0', 'Var_Class 1', 'Var_Class 2']))print('Mean Absolute Error:', metrics.mean_absolute_error(y3_test, y3_pred_ppn))print('Mean Squared Error:', metrics.mean_squared_error(y3_test, y3_pred_ppn))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y3_test, y3_pred_ppn)))#precision:reali positivi, maggiore è, minore errore di falsi positivi#recall:percentuale valori predetti correttamente, quindi se elevata sono stati predetti pochi positivi#nella classe di negativi#### CROSS VALIDATION## definisco il datasetX, y = make_classification() # NON RUNNO ORA## definisco il modellomodelLRovr = LogisticRegression(multi_class='ovr')scores_lr = cross_val_score(modelLRovr, X, y, cv=5)scores_lrprint("Accuracy: %0.2f (+/- %0.2f)" % (scores_lr.mean(), scores_lr.std() * 2))#0.43scoring_lr = ['precision_macro', 'recall_macro']scores_lr_2 = cross_validate(modelLRovr, X, y, scoring=scoring_lr)sorted(scores_lr_2.keys())scores_lr_2['test_precision_macro']scores_lr_2['test_recall_macro']### ALTERNATIVA SU COME SCRIVERE IL CODICE PER OVR#########################OneVsRestClassifier#############################################al posto di clf possiamo mettere qualsiasi altra robaclf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)y_pred = clf.predict(X_test)accuracy_score(y_test, y_pred) #0.43#### PROVA 3 da sistemare ??pipe = Pipeline([('sampl', SMOTEENN()),                 ('clf', MultinomialNB())])ovr = OneVsRestClassifier(pipe)ovr.fit(X, y)######### PERCEPTRON #########X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)np.array(y_test)np.array(y_train)# creo il modello previsionale con Perceptron e definisco i parametri#imposto un max di iterazioni pari a 40, tol indica l'indice di tolleranza#sufficiente per l'uscita dal ciclo, eta indica tasso di apprendimento del#modello.### CROSS VALIDATION PERCEPTRON ###ppn = Perceptron(max_iter=40, tol=0.001, eta0=0.01, random_state=0)scores_ppn = cross_val_score(ppn, X, y, cv=2)scores_ppnprint("Accuracy: %0.2f (+/- %0.2f)" % (scores_ppn.mean(), scores_ppn.std() * 2))#0.47########### DA NON CONSIDERAREtrainingnots_kit_id1 = trainingnots_kit_id1.drop(trainingnots_kit_id1.loc[trainingnots_kit_id1['KIT_ID']=='1629361016'].index)trainingnots_kit_id1.drop(trainingnots_kit_id1.loc[trainingnots_kit_id1['KIT_ID']=='2487219358'].index, inplace=True)print(trainingnots_kit_id1[trainingnots_kit_id1['VAR_CLASS']==1])